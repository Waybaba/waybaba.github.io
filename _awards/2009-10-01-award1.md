---
title: "SRNet: Structured Relevance Feature Learning Network from Skeleton Data for Human Action Recognition"
collection: awards
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2019-10-01
venue: 'IEEE Access'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Wei Wang. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
## Abstract

In recent years, human action recognition based on skeleton information has recently drawn increasing attentions with published of large-scale skeleton datasets. The most crucial factors for this task line in two aspects: the intra-frame representation for joint co-occurrences and the inter-frame representation for skeletons' temporal evoluations. The most effective ways focus on the spontaneous features extraction by using deep learning. As we know, these are not so many methods fully consider the structure information of skeleton joints and the correlation between two different skeleton joints for human action recognition. Most of the former works can not stress the human-aware relationships between some joints like symmetry and keep the free feature extraction abilities of deep learning networks at the same time. In this paper, we do not simply treat the joints position information as unordered points. Instead, we employ a special data reorganizing strategy to represent the global and local structure information of human skeleton. Meanwhile, we also employ the data mirror to increase the relationship between skeleton joints by fully consider the structure information of human. Based on this design, we proposed an end-to-end multi-dimentional CNN network to fully consider the spatial and temporal information to learn the feature extraction transform. Specifically, in this CNN network, we employ different convolution kernels on different dimensions to learn skeleton represent from spatial and temporal viewpoint in order to make the most of human structural information to generate robust features. We compare with other state-of-the-arts on action recognition dataset like NTU RGB+D, PKU-MMD SYSU and U-Kinect. The experimental results also demonstrate the superiority of our method. 

## keywords

Convolutional Neural Network, Deep learning, Human activity recognition, Human skeleton information

[Download paper here](http://academicpages.github.io/files/paper1.pdf)

Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1).